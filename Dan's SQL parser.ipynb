{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '''\n",
    "manufacture.produce_task as pt\n",
    "SELECT\n",
    "\ta.*,\n",
    "\ta.实际合格产出 + a.实际不合格产出 AS 实际总产出 \n",
    "FROM\n",
    "\t(\n",
    "\tSELECT\n",
    "\t\tpt.process_name 工序名称,\n",
    "\t\tpt.process_code 工序编号,\n",
    "\t\tpt.process_name 工序简称,\n",
    "\t\tSUM( pt.amount_product_planned ) 计划数,\n",
    "\t\t( CASE WHEN ISNULL( SUM( shr.amount_hold ) ) THEN 0 ELSE SUM( shr.amount_hold ) END ) 实际合格产出,\n",
    "\t\t( CASE WHEN ISNULL( SUM( shur.amount_diff ) ) THEN 0 ELSE SUM( shur.amount_diff ) END ) 实际不合格产出 \n",
    "\tFROM\n",
    "\t\t( SELECT * FROM manufacture.produce_task WHERE org_id = 610009 ) pt\n",
    "\t\tINNER JOIN (\n",
    "\t\tSELECT\n",
    "\t\t\tshr.task_id,\n",
    "\t\t\tshr.org_id,\n",
    "\t\t\tSUM( shr.amount_hold ) amount_hold,\n",
    "\t\t\tcreated_at \n",
    "\t\tFROM\n",
    "\t\t\tmanufacture.scan_hold_record shr \n",
    "\t\tWHERE\n",
    "\t\t\tDATE( created_at ) = CURDATE( ) \n",
    "\t\tGROUP BY\n",
    "\t\t\tshr.task_id \n",
    "\t\t) shr ON shr.task_id = pt.id \n",
    "\t\tAND shr.org_id = pt.org_id\n",
    "\t\tLEFT JOIN ( SELECT org_id, task_id, sum( amount_diff ) amount_diff, created_at FROM manufacture.scan_hold_unqualified_record WHERE DATE( created_at ) = CURDATE( ) GROUP BY task_id ) AS shur ON shur.org_id = pt.org_id \n",
    "\t\tAND shur.task_id = pt.id \n",
    "\tWHERE\n",
    "\t\tpt.org_id = 610009 \n",
    "\tGROUP BY\n",
    "\tpt.process_code \n",
    "\t) a'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库  :  表 \n",
      "\n",
      "manufacture : ['produce_task', 'scan_hold_record', 'scan_hold_unqualified_record'] \n",
      "\n",
      "\t produce_task : ['pt'] \n",
      "\n",
      "\t\t共 5 个字段: ['amount_product_planned', 'id', 'org_id', 'process_code', 'process_name']\n",
      "\t scan_hold_record : ['shr'] \n",
      "\n",
      "\t\t共 3 个字段: ['amount_hold', 'org_id', 'task_id']\n",
      "\n",
      "\t scan_hold_unqualified_record :未重命名 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pat1 = re.compile(r'FROM +((?!\\()\\w+?)\\.')\n",
    "pat2 = re.compile(r'FROM\\n\\t*((?!\\()\\w+?)\\.')\n",
    "pat3 = re.compile(r'LEFT JOIN +((?!\\()\\w+?)\\.')\n",
    "pat3_AS = re.compile(r'LEFT JOIN +AS ((?!\\()\\w+?)\\.')\n",
    "\n",
    "pat1l = re.compile(r'from +((?!\\()\\w+?)\\.')\n",
    "pat2l = re.compile(r'from\\n*\\t*((?!\\()\\w+?)\\.')\n",
    "pat3l = re.compile(r'left join +((?!\\()\\w+?)\\.')\n",
    "pat3l_as = re.compile(r'left join +as ((?!\\()\\w+?)\\.')\n",
    "r = list(set(re.findall(pat1,string) + re.findall(pat2,string) + re.findall(pat1l,string) + re.findall(pat2l,string) + \n",
    "       re.findall(pat3,string) + re.findall(pat3_AS,string) + re.findall(pat3l,string)+ re.findall(pat3l_as,string)))\n",
    "#提取库名\n",
    "\n",
    "print ('库  :  表','\\n')\n",
    "\n",
    "for item in r:\n",
    "    p = re.compile(item+r'\\.([^ \\n](?!\\{)(?!\\$)\\w+)')\n",
    "    temp = list(set(re.findall(p,string)))\n",
    "    temp.sort()\n",
    "    # 提取表名\n",
    "    print (item,':',temp,'\\n')\n",
    "    temp.append('-------------------------')\n",
    "    \n",
    "    item = '库:'+item\n",
    "    df2 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame(columns = [item], data = temp)\n",
    "    df2.to_csv('/Users/data/desktop/table.csv', mode = 'a', index = False)\n",
    "    # 输出「库：表」\n",
    "    temp = temp[:-1]\n",
    "    \n",
    "    for table in temp:\n",
    "        p_1 = re.compile(r'\\.'+table+r' +((?!where)(?!WHERE)(?!as)(?!AS)\\w+)')\n",
    "        p_2 = re.compile(r'\\.'+table+r' +AS (\\w+)')\n",
    "        p_2l = re.compile(r'\\.'+table+r' +as (\\w+)')\n",
    "        alias = list(set(re.findall(p_1,string)+re.findall(p_2,string)+re.findall(p_2l,string)))\n",
    "        if alias:\n",
    "            print ('\\t',table,':',alias,'\\n')\n",
    "        else:\n",
    "            print ('\\n\\t',table,':未重命名','\\n')\n",
    "        #提取表的重命名\n",
    "        \n",
    "        ziduan = []\n",
    "        \n",
    "        if alias:\n",
    "            for i in alias:\n",
    "                p_3 = re.compile(r' '+i+'\\.(\\w+)')\n",
    "                p_4 = re.compile(r', *'+i+'\\.(\\w+)')\n",
    "                p_5 = re.compile(r'= *'+i+'\\.(\\w+)')\n",
    "                p_6 = re.compile(r'\\( *'+i+'\\.(\\w+)')\n",
    "                p_7 = re.compile(r'\\n *\\t*'+i+'\\.(\\w+)')\n",
    "                ziduan = list(set(ziduan+list(set(re.findall(p_3,string)+re.findall(p_4,string)\n",
    "                                       +re.findall(p_5,string)+re.findall(p_6,string)+re.findall(p_7,string)))))\n",
    "                ziduan = list(set(list(map(lambda x: x.lower(), ziduan ))))\n",
    "            \n",
    "            ziduan.sort() \n",
    "            #将字段按首字母进行排序\n",
    "            \n",
    "            print ('\\t\\t共',len(ziduan),'个字段:',ziduan)\n",
    "            ziduan.append('-------------------------')\n",
    "            \n",
    "            table = '表:'+table\n",
    "            df = pd.DataFrame()\n",
    "            df = pd.DataFrame(columns = [table], data = ziduan)\n",
    "            df.to_csv('/Users/data/desktop/ziduan.csv', mode = 'a', index = False)\n",
    "            #提取字段并输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
